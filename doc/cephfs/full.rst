处理占满的 Ceph 文件系统
========================

当 RADOS 集群使用率达到总容量的 ``mon_osd_full_ratio`` （默认 95% ）时，它\
会被打上 OSD full 标记。在问题解决前（如扩容集群），此标记会使大多数常规 \
RADOS 客户端暂停所有操作。

文件系统对 full 标记还有些特殊处理，下文详述。


Hammer 及更高版
---------------

从 hammer 发布开始，以下行为会导致占满的文件系统返回 ENOSPC 错误：

 * 客户端写入数据
 * 删除和裁剪以外的其它元数据操作

因为只有在数据刷回到硬盘（有时是 ``write`` 返回 0 之后）才可能遇到占满的情\
况，所以应用程序调用 ``fsync`` 或 ``fclose`` （或等价操作）进行文件处理时才\
可能遇到 ENOSPC 错误。

调用 ``fsync`` 能可靠地反映数据是否写入了硬盘，并且在没写入时返回错误。 \
``fclose`` 只有在缓冲的数据从上次写入以来被偶尔刷回过才会返回错误［译者：原\
文可能有误］—— ``fclose`` 成功并不能保证数据写入了硬盘，而且在空间占满时， \
``fclose`` 之后如果没地方存储缓冲的数据，它们就可能被丢弃。

.. warning::
    如果某一应用程序在占满的文件系统上行为异常，有必要检查下它调用了 \
    ``fsync()`` 来确保数据已写入硬盘，然后再继续。

如果客户端运行时已经看到了 OSD full 标记，写数据操作可能被取消。各个客户端取\
消操作并释放文件能力时会更新 ``osd_epoch_barrier`` ，以确保这些取消的操作不\
会妨碍 MDS 或其它客户端对这些数据对象的访问。要了解元图屏蔽机制，请参考 \
:doc:`eviction` 。


老版本（ hammer 之前）的行为
----------------------------

在 hammer 之前的 Ceph 版本中， MDS 会忽略 RADOS 集群的占满状态，而且客户端的\
任意数据写入都会卡死，直到集群脱离占满状态。

出现这种行为时有两种危险情形要注意：

* 如果一客户端到一个文件的写入未完成，那么它不可能把文件释放给 MDS 让它删\
  除，这样就很难清理占满的文件系统。
* 如果客户端持续地创建大量空文件，来自 MDS 的元数据写入操作终将会耗尽 OSD \
  空间，这样就再也不能执行删除动作了。

